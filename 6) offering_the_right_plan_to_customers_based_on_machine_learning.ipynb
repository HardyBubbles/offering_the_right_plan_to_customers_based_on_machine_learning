{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание проекта**  \n",
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится, так как выполнялась на одном из предудущих этапах.\n",
    "Постройте модель с максимально большим значением accuracy. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте `accuracy` на тестовой выборке самостоятельно.  \n",
    "\n",
    "**Описание данных**  \n",
    "  * сalls — количество звонков;\n",
    "  * minutes — суммарная длительность звонков в минутах;\n",
    "  * messages — количество sms-сообщений;\n",
    "  * mb_used — израсходованный интернет-трафик в Мб;\n",
    "  * is_ultra — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).  \n",
    "  \n",
    "**Ход выполнения:**\n",
    "  1) Откроем файл с данными и изучим его. Путь к файлу: /datasets/users_behavior.csv;  \n",
    "  2) Разделим исходные данные на обучающую, валидационную и тестовую выборки;  \n",
    "  3) Исследуем качество разных моделей, меняя гиперпараметры. Кратко составим выводы исследования;  \n",
    "  4) Выполним проверку качества модели на тестовой выборке;  \n",
    "  5) Дополнительное задание: проверить модели на вменяемость.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые инструменты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем датафрейм в пременную и ознакомимся с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pth1 = '/datasets/users_behavior.csv'\n",
    "pth2 = 'C:/Users/username/Desktop/users_behavior.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    df = pd.read_csv(pth1)\n",
    "elif os.path.exists(pth2):\n",
    "    df = pd.read_csv(pth2)\n",
    "else:\n",
    "    print('Check the PATH to data file please')\n",
    "    \n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как тип данных в столбце `is_ultra int64`, то хорошо бы проверить на отсутствие значений, отличных от 0 и 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод команды говорит нам о том, что столбец `is_ultra` не содержит других значений, кроме 0 и 1. А с учётом вывода команды `info()`, показавшей отсутствие пропусков, получается, что все данные у нас размечены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:  \n",
    "Согласно выводу команды `info()`, все строки заполнены, пропусков нет. Заголовки корректные и содержимое столбцов не вызывает нареканий по первому взгляду, другими словами, данные подготовлены к дальнейшей работе с ними."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы формируем три выборки из одного набора данных, то функцией `train_test_split` разбиваем его в следующих пропорциях:\n",
    "обучающая (60%), валидационная (20%) и тестовая (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# первой отделим тестовую выборку, оставшиеся 80% датасета сохраним во временную переменную\n",
    "df_80, df_test = train_test_split(df, test_size=.2, random_state=12345)\n",
    "# с учётом изменившихся пропорций делим свободный датасет на валидационную и обучающие выборки\n",
    "df_train, df_valid = train_test_split(df_80, test_size=.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1928 entries, 2656 to 510\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     1928 non-null   float64\n",
      " 1   minutes   1928 non-null   float64\n",
      " 2   messages  1928 non-null   float64\n",
      " 3   mb_used   1928 non-null   float64\n",
      " 4   is_ultra  1928 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 90.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 2699 to 1806\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      " 4   is_ultra  643 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 1415 to 1196\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      " 4   is_ultra  643 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк в датасете и выборках совпадает!\n"
     ]
    }
   ],
   "source": [
    "# выводим на экран и проверяем содержимое выборок\n",
    "display(df_train.info())\n",
    "display(df_valid.info())\n",
    "display(df_test.info())\n",
    "# небольшая проверка на полноту\n",
    "if len(df) == (len(df_train) + len(df_valid) + len(df_test)):\n",
    "    print('Количество строк в датасете и выборках совпадает!')\n",
    "else:\n",
    "    print('Количество строк в датасете и выборках НЕ совпадает!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:  \n",
    "Исходный датасет был успешно разделён на три выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исслкдовать мы будем 3 модели: Дерево решений, Случайный лес и Логистическую регрессию.  \n",
    "Можно сразу подготовить выборки, разделив их на пространство признаков и целевые признаки (`is_ultra`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель будем запускать в цикле с подбором её основного гиперпараметра - глубины дерева.  \n",
    "Как показывает наш предыдущий опыт больше 5 уровней нет смысла делать дерево, так как модель переобучается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший показатель глубины дерева: 3\n",
      "Лучший показатель accurancy: 0.7651632970451011\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_depth = 0\n",
    "best_model_tr = None\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    # обучаем модель\n",
    "    model.fit(features_train, target_train)\n",
    "    # предсказываем целевой признак для валидационной выборки\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    # проверяем accurancy для валидационной выборки\n",
    "    result = accuracy_score(target_valid, predictions_valid)\n",
    "    \n",
    "    # сохраняем лучшие значения\n",
    "    if result > best_result:\n",
    "        best_depth = depth\n",
    "        best_result = result\n",
    "        best_model_tr = model\n",
    "\n",
    "print('Лучший показатель глубины дерева:', best_depth)\n",
    "print('Лучший показатель accurancy:', best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель также запускаем в цикле, с подбором сразу трёх гиперпараметров: количество деревьев в лесу, глубина каждого и количество элементов в листе.  \n",
    "Количество деревьев будем менять от 10 до 100 с шагом 10, глубину от 1 до 5, кол-во элементов в листьях от 1 до 3.  \n",
    "Обучим каждую полученную модель на обучающей выборке, проверим результат обучения на валидационной выборке и выберем из них лес с максимальной долей правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший показатель accurancy при кол-ве деревьев: 90\n",
      "Лучший показатель accurancy при глубине: 5\n",
      "Лучший показатель accurancy при кол-ве элементов в листе: 2\n",
      "Лучший показатель accurancy: 0.7838258164852255\n"
     ]
    }
   ],
   "source": [
    "best_model_fr = None\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "best_sample = 0\n",
    "best_result = 0\n",
    "\n",
    "\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range(1, 6):\n",
    "        for sample in range(1, 4):\n",
    "            model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth, min_samples_leaf=sample)\n",
    "            # обучаем модель\n",
    "            model.fit(features_train, target_train)\n",
    "            # проверяем результат\n",
    "            result = model.score(features_valid, target_valid)\n",
    "            if result > best_result:\n",
    "                best_model_fr = model\n",
    "                best_est = est\n",
    "                best_depth = depth\n",
    "                best_sample = sample\n",
    "                best_result = result\n",
    "\n",
    "print('Лучший показатель accurancy при кол-ве деревьев:', best_est)\n",
    "print('Лучший показатель accurancy при глубине:', best_depth)\n",
    "print('Лучший показатель accurancy при кол-ве элементов в листе:', best_sample)\n",
    "print('Лучший показатель accurancy:', best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель логистической регрессии, обучаем на обучающей выборке, проверяем на валидационной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели: 0.7262830482115086\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "# обучаем\n",
    "model_lr.fit(features_train, target_train)\n",
    "# предсказываем значение целевого признака\n",
    "predictions_valid = model_lr.predict(features_valid)\n",
    "# проверяем точность\n",
    "accuracy = model_lr.score(features_valid, target_valid)\n",
    "print('Точность модели:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:  \n",
    "Наилучший показатель точности продемонстрировала модель \"Случайный лес\" - 78.4%\n",
    "Подобранные гиперпараметры: кол-во деревьев - 90, глубина - 5, кол-во элементов в листе - 2.  \n",
    "Её и будем использовать для дальнейше проверки на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.7916018662519441\n"
     ]
    }
   ],
   "source": [
    "# здесь теперь можно использовать для обучения совокупность признаков из обучающей и валидационной выборок\n",
    "features_train_80 = df_80.drop(['is_ultra'], axis=1)\n",
    "target_train_80 = df_80['is_ultra']\n",
    "\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=90, max_depth=5, min_samples_leaf=2)\n",
    "# обучаем модель\n",
    "model.fit(features_train_80, target_train_80)\n",
    "# проверяем результат\n",
    "result = model.score(features_test, target_test)\n",
    "\n",
    "print('Точность на тестовой выборке:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:  \n",
    "Модель с оптимизированными гиперпараметрами на тестовой выборке показала точность немного лучше, чем на валидационной - 79.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на адекватность - это сравнение основного показателя качества для модели-глупышки и специально обученной.  \n",
    "В качестве глупышки воспользуемся DummyClassifier, долю правильных ответов посчитаем с параметром `strategy='most_frequent'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6951788491446346"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вызываем модель\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "# обучаем\n",
    "dummy.fit(features_train, target_train)\n",
    "# предсказываем\n",
    "dummy.predict(features_test)\n",
    "# смотрим точность\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:  \n",
    "Полученная нами модель \"Случайный лес\" успешно проходит проверку на адекватность, так как доля её верных ответов выше, чем при случайном угадывании: 79% против 69.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод по проведённому исследованию:  \n",
    "  1) В исследовании участвовали три различные алгоритма классификации: дерево решений, случайный лес и логистическая регрессия.  \n",
    "  2) Для проведения обучения, проверки моделей и тестирования лучшей модели исходный датафрейм был разделён на три выборки: обучающую (60%), валидационную (20%) и тестовую (20%).  \n",
    "  3) По итогам исследования можно сделать заключение о том, что для получения рекомендации тарифных планов наиболее подходящей моделью является модель, построенная на случайном лесе с количеством деревьев 90, глубиной каждого отдельного дерева 5 и количеством образцов в листе 2 - доля правильных ответов в тестовой выборке составила 79.1%  \n",
    "  4) При проверке модели на адекватность сделан вывод, что она показывает намного лучший результат, чем модель с примитивным прогнозом."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1433,
    "start_time": "2023-03-14T10:50:42.756Z"
   },
   {
    "duration": 106,
    "start_time": "2023-03-14T11:29:28.222Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-14T11:30:43.769Z"
   },
   {
    "duration": 118,
    "start_time": "2023-03-14T11:35:43.475Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-14T11:35:51.006Z"
   },
   {
    "duration": 29,
    "start_time": "2023-03-14T11:35:51.909Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-14T11:36:49.110Z"
   },
   {
    "duration": 55,
    "start_time": "2023-03-14T11:43:36.577Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-14T17:13:00.916Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-14T17:14:08.086Z"
   },
   {
    "duration": 95,
    "start_time": "2023-03-14T17:14:08.728Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-14T17:14:09.870Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-14T17:39:26.186Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-14T17:39:51.007Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-14T17:43:57.631Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-14T17:44:23.108Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-14T18:00:17.474Z"
   },
   {
    "duration": 44,
    "start_time": "2023-03-14T18:21:19.083Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-14T18:41:31.286Z"
   },
   {
    "duration": 18051,
    "start_time": "2023-03-14T18:51:00.964Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-14T19:22:53.178Z"
   },
   {
    "duration": 19173,
    "start_time": "2023-03-14T19:23:00.688Z"
   },
   {
    "duration": 17698,
    "start_time": "2023-03-14T19:25:04.600Z"
   },
   {
    "duration": 61,
    "start_time": "2023-03-14T19:28:19.949Z"
   },
   {
    "duration": 265,
    "start_time": "2023-03-14T19:39:20.468Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-14T19:59:32.187Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-14T20:07:00.317Z"
   },
   {
    "duration": 1172,
    "start_time": "2023-03-14T20:07:12.480Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-14T20:07:13.662Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-14T20:07:13.726Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-14T20:07:13.733Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-14T20:07:13.759Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-14T20:07:13.812Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-14T20:07:13.819Z"
   },
   {
    "duration": 16510,
    "start_time": "2023-03-14T20:07:13.864Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-14T20:07:30.375Z"
   },
   {
    "duration": 262,
    "start_time": "2023-03-14T20:07:30.414Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-14T20:07:30.679Z"
   },
   {
    "duration": 1911,
    "start_time": "2023-03-14T20:15:58.562Z"
   },
   {
    "duration": 92,
    "start_time": "2023-03-14T20:16:00.475Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-14T20:16:00.570Z"
   },
   {
    "duration": 58,
    "start_time": "2023-03-14T20:16:00.577Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-14T20:16:00.637Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-14T20:16:00.719Z"
   },
   {
    "duration": 64,
    "start_time": "2023-03-14T20:16:00.732Z"
   },
   {
    "duration": 16979,
    "start_time": "2023-03-14T20:16:00.798Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-14T20:16:17.779Z"
   },
   {
    "duration": 250,
    "start_time": "2023-03-14T20:16:17.820Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-14T20:16:18.072Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
